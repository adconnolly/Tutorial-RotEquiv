{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332f094a-2962-4601-af65-47e42873911a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "!pip install wget\n",
    "import numpy as np\n",
    "!pip install e2cnn\n",
    "import e2cnn\n",
    "import torch\n",
    "from sklearn.metrics import r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "!pip install torchsummary\n",
    "from torchsummary import summary\n",
    "from util import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61336f3-8f84-43c7-903d-62828d3beef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf40feb-1b64-4190-aba8-aac7a895bcee",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910fc10f-c0fe-46a0-b458-2edc476f8741",
   "metadata": {},
   "source": [
    "Let's get some data to play with. \\\n",
    "I have made available for download some data, using the function below, but it would be more fun to upload your own data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb578bb9-7250-4265-bef8-93857d239cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4dec28-fbeb-422a-8425-d441acc4e17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca100668-bb3f-491a-9480-e2cf03067cd0",
   "metadata": {},
   "source": [
    "For those uploading their own data: \\\n",
    "Make sure you have O(10) timesteps and preferably multiple vertical levels of at least one 2-d vector in the horizontal plane and preferably one 'scalar' (which could be vertical velocity component) as inputs. Let's start with just one output variable. \\\n",
    "Data should be colocated, so some de-staggering may be in order."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fec8089-90a2-4e37-9dc7-39a3b4aa9fea",
   "metadata": {},
   "source": [
    "For those who want to use my data: \\\n",
    "While waiting for others to upload, please try to debug the get_data() function in util.py which currently needs to use wget though I feel xr.open_dataset should suffice. \\\n",
    "Or, modify the code below to use xarray, or any other library you think is useful, instead of numpy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c36a64a-8093-47cf-a646-0ff08b4c6ee6",
   "metadata": {},
   "source": [
    "## Brief preproccessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc3e429-0d82-4cb1-b64b-a3e0607e242c",
   "metadata": {},
   "source": [
    "First, let's reorder the time index as our sample index and our z-index as a channel index for 2-d convolution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1394bf70-f7f0-4dc4-9592-f29778b6a12e",
   "metadata": {},
   "source": [
    "My data's index order was originally (z,y,x,t) so the details of the transpose might change if using your own data. \\\n",
    "Index order should be (sample, channel=vertical level, x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1731f4-6fc1-418f-9d67-c170690461d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ustd=np.std(np.sqrt(ds['u'].values**2+ds['v'].values**2))\n",
    "\n",
    "u=np.transpose(scale(ds['u'].values,std=Ustd), [3,0,1,2]) \n",
    "v=np.transpose(scale(ds['v'].values,std=Ustd), [3,0,1,2])\n",
    "w=np.transpose(scale(ds['w'].values) , [3,0,1,2])\n",
    "tau12=np.transpose(scale(ds['tau12'].values), [3,0,1,2])\n",
    "nz=u.shape[1] # might need to change index for your data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5febf23-8d9e-4a49-9da8-cd1c5bf91b78",
   "metadata": {},
   "source": [
    "In the next step we will concatenate the input variables along the channel dimension.\n",
    "At this point, we lose the information that the two components of the vector are related to each other geometrically.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13fe831-c479-4909-9aca-fae00644c4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputFields = np.concatenate((u, v, w),axis=1)\n",
    "outputFields = tau12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad5b364-7df3-4a10-b844-6498fd1e91e1",
   "metadata": {},
   "source": [
    "## A pytorch baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38315f09-fc71-47a8-9bda-2c8ea95d94ac",
   "metadata": {},
   "source": [
    "Let's make a simple pytorch CNN to compare to an equivariant CNN, which we will construct later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58dabe8-d920-4dcd-bab6-e63cabf47df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class pytorchCNN(torch.nn.Module):\n",
    "    def __init__(self, input_shape, nz):\n",
    "        super(pytorchCNN, self).__init__()\n",
    "        \n",
    "        C=input_shape[1]*np.array([2,2]) # number of channel in hidden layers\n",
    "        \n",
    "        self.conv1 = torch.nn.Conv2d(input_shape[1], C[0], kernel_size=3,padding=1,padding_mode='circular')\n",
    "        self.relu1 = torch.nn.ReLU()\n",
    "        self.conv2 = torch.nn.Conv2d(C[0], C[1], kernel_size=3,padding=1,padding_mode='circular')\n",
    "        self.relu2 = torch.nn.ReLU()\n",
    "        self.conv3 = torch.nn.Conv2d(C[1], nz, kernel_size=3,padding=1,padding_mode='circular')\n",
    "        \n",
    "    def forward(self,x):\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.conv3(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec8a4e7-913a-463f-b579-f71341c852a4",
   "metadata": {},
   "source": [
    "Let's split our data into training and validation, uisng the mask below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bd2221-30c7-4ba2-8c50-b49cfe826eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask =  np.random.rand(inputFields.shape[0]) < 0.80"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa3e746-5c81-439f-b2f9-b0e7bbc4f51b",
   "metadata": {},
   "source": [
    "In addition to splitting the data, the next cell will convert to the appropriate data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a3115a-2546-4c47-b735-4918c19ec4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test = torch.from_numpy(inputFields[mask]).float().to(device), torch.from_numpy(inputFields[~mask]).float().to(device)\n",
    "y_train, y_test = torch.from_numpy(outputFields[mask]).float().to(device), torch.from_numpy(outputFields[~mask]).float().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73f372a-75fc-402e-8880-ebe5f8117f8b",
   "metadata": {},
   "source": [
    "Instantiating our model below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af62aee-0c69-4203-a5b6-ce65a61b086b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=pytorchCNN(x_train.shape,nz).float().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931a6a05-e7c0-462b-b182-ed57d4311ae6",
   "metadata": {},
   "source": [
    "Some reasonable choices for optimizer and loss function below. Feel free to change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15dce1f5-c590-4e59-a4cb-1fd4e5ba2165",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters())#,lr=0.001)\n",
    "criterion = torch.nn.MSELoss() # MSE loss function\n",
    "validation_loss = list()\n",
    "train_loss = list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e47723f-0353-4ce4-a745-a9054c059aaa",
   "metadata": {},
   "source": [
    "Training loop, nothing fancy. \\\n",
    "If you want the loss to be printed after every epoch, uncomment the commented lines and comment the two below those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45dbe4b8-1b5f-4831-8fd4-ac007a1f2a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 200 #Number of epochs\n",
    "for epoch in range(n_epochs):\n",
    "    train_model(model,x_train,y_train,criterion,optimizer)\n",
    "    # train_loss.append(test_model(model,x_train,y_train,criterion,optimizer, 'train'))\n",
    "    # validation_loss.append(test_model(model,x_test,y_test,criterion,optimizer))\n",
    "    train_loss.append(test_model(model,x_train,y_train,criterion,optimizer, None))\n",
    "    validation_loss.append(test_model(model,x_test,y_test,criterion,optimizer,None))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e497d9ce-dfb4-4fd6-8fd7-9183ac1c3dbf",
   "metadata": {},
   "source": [
    "Loss curves below don't have to be perfect, we just need some reasonable level of performance so we can make sense of the contour plots below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09e490a-ad23-4891-98df-2e11162f5ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_losses(validation_loss,train_loss)\n",
    "plot_losses(validation_loss,train_loss,startEpoch=len(validation_loss)-10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22379b24-07f2-4558-ba52-ea938a73ef15",
   "metadata": {},
   "source": [
    "Now, we plot some predictions from the validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f48849-29f0-4fb8-b9ac-9cfb66507de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction=model(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5113b5e2-5029-4d20-9c90-31f4474529d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "kplot=nz//2\n",
    "tplot=y_test.shape[0]//2\n",
    "\n",
    "plot_contour(y_test,prediction,tplot,kplot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568621fb-048f-4ec2-b11b-c529f02c60b5",
   "metadata": {},
   "source": [
    "To reiterate, the performance does not need to be optimized, because the focus will be on how the model does on unrotated vs rotated data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5ad3b4-cc71-4e52-92e2-4d851d1a1fbe",
   "metadata": {},
   "source": [
    "Now, we need some rotated data! \\\n",
    "I wrote the function, myrotate, specifically for rotating the velocity vector, ordered as below (u,v,w) and the outputField, tau_12. Tau_12 doesn't rotate exactly like a scalar, if your output does, delete the input, out_type, in the myrotate() call. If it still doesn't work for you, don't worry you'll get a chance to write your own rotate function later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8fb000-cc96-4b99-8dfd-89c2c2ddabde",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputFields_rotated,outputFields_rotated = myrotate(np.stack((u,v,w)),outputFields,krot=1,out_type='sign')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb295c6-76e1-4db2-8304-4ceccb3930b1",
   "metadata": {},
   "source": [
    "Because rotating didn't affect the time/sample dimension, we'll use the same mask as during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b90cbe-7ff3-430e-b5d8-2b89217ebc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_rotated, x_test_rotated = torch.from_numpy(inputFields_rotated[mask]).float().to(device), torch.from_numpy(inputFields_rotated[~mask]).float().to(device)\n",
    "y_train_rotated, y_test_rotated = torch.from_numpy(outputFields_rotated[mask]).float().to(device), torch.from_numpy(outputFields_rotated[~mask]).float().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335f45c6-8625-4f16-976c-0fd12333e7ee",
   "metadata": {},
   "source": [
    "The following plots are just to establish that our rotations work. If you didn't delete the out_type=sign input to myrotate() and notice and sign error in the bottom plot, try deleting that now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d1b5b2-fa6f-4e12-bf06-624e3a61e019",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_quiver( [x_test[:,0:nz],x_test[:,nz:2*nz]],[x_test_rotated[:,0:nz],x_test_rotated[:,nz:2*nz]],tplot,kplot)\n",
    "plot_contour(x_test[:,0:nz],x_test_rotated[:,nz:2*nz],tplot,kplot,text=['Original, u','Rotated, v'])\n",
    "plot_contour(x_test[:,nz:2*nz],-x_test_rotated[:,0:nz],tplot,kplot,text=['Original, v','Rotated, -u'])\n",
    "plot_contour(x_test[:,-nz:],x_test_rotated[:,-nz:],tplot,kplot,text=['Original, w','Rotated, w'])\n",
    "plot_contour(y_test,-y_test_rotated,tplot,kplot,text=['Original, tau_12','Rotated, -tau_12'],clim_mode='share')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbb45ee-6350-4557-9306-3416a459db3a",
   "metadata": {},
   "source": [
    "If your inputs and outputs are rotating correctly, time to test our prediction on roated inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52499f34-a847-4730-9c5e-d9c7b60eeb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_rotated=model(x_test_rotated)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743bd93f-178b-4249-902d-7b1a845770eb",
   "metadata": {},
   "source": [
    "Again, there is a negative sign below relating to the type of tau_12, modify if necessary for your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e7e50e-e327-4ee6-8c21-ba6b9872346f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_contour(y_test,prediction,tplot,kplot)\n",
    "plot_contour(-y_test_rotated,-prediction_rotated,tplot,kplot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab9678b-38bc-4dca-b891-262c91b95dd5",
   "metadata": {},
   "source": [
    "The take-away here is that the pytorch baseline, albeit without data augmentation, has absolutely no predictive skill when ingesting rotated input data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206011d3-d3d4-416d-96ff-d6f35db890f8",
   "metadata": {},
   "source": [
    "## e2cnn version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66cd0ab-a3b3-4a4d-b8d1-8f4eb0dae737",
   "metadata": {},
   "source": [
    "Compare the pytorch code, pasted below for convenience, to the e2cnn version of the same network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fb565b-b6f6-4d84-a34d-101e4faae46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class pytorchCNN(torch.nn.Module):\n",
    "    def __init__(self, input_shape, nz):\n",
    "        super(pytorchCNN, self).__init__()\n",
    "        \n",
    "        C=input_shape[1]*np.array([2,2]) # number of channel in hidden layers\n",
    "        \n",
    "        self.conv1 = torch.nn.Conv2d(input_shape[1], C[0], kernel_size=3,padding=1,padding_mode='circular')\n",
    "        self.relu1 = torch.nn.ReLU()\n",
    "        self.conv2 = torch.nn.Conv2d(C[0], C[1], kernel_size=3,padding=1,padding_mode='circular')\n",
    "        self.relu2 = torch.nn.ReLU()\n",
    "        self.conv3 = torch.nn.Conv2d(C[1], nz, kernel_size=3,padding=1,padding_mode='circular')\n",
    "        \n",
    "    def forward(self,x):\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.conv3(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060fc119-f386-4a3f-bb4d-79fe1e1fb253",
   "metadata": {},
   "source": [
    "First, note the forward() routines look almost identical. The only difference is that I convert the input tensor, x, to the e2cnn data type, GeometricTensor. This is basically a fancy wrapper around the torch Tensor data type, which adds the geometric information. \\\n",
    "Where does this geometric information come from? That is encoded in self.type_in which I define with e2cnn.nn.FieldType during the init. Indeed, defining these FieldType objects is most of the extra code in the e2cnn init compared to that of the pytorch baseline. \\\n",
    "In the calls to R2Conv, another fancy wrapper around pytorch's Conv2d, the FieldType plays the role of the channels in and channels out."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3141d8d7-73d7-40fb-be30-5fb04647ca91",
   "metadata": {},
   "source": [
    "Other than defining the dimensionality of the convolutions, the e2cnn.nn.FieldType objects says with what kind of 'representation' each feature is associated. The represention of the transformations of a particular input have a certain 'irrep' which may correspond to familiar scalar, irrep(0), and vector, irrep(1), inputs. The output is associated with the less familiar 'sign' representation, irrep(2), discussed in the presentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2398f9-1b83-4d22-95f2-ebf62fae27b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class e2cnnCNN(torch.nn.Module):\n",
    "    def __init__(self, input_shape, nz):\n",
    "        super(e2cnnCNN, self).__init__()\n",
    "        \n",
    "        C=input_shape[1]*np.array([2,2]) # number of channel in hidden layers\n",
    "        \n",
    "        C4group = e2cnn.gspaces.Rot2dOnR2(N = 4)\n",
    "        self.type_in = e2cnn.nn.FieldType(C4group, nz*[C4group.irrep(1)]+nz*[C4group.trivial_repr])\n",
    "        self.type_hid1 = e2cnn.nn.FieldType(C4group, C[0]*[C4group.regular_repr])\n",
    "        self.type_hid2 = e2cnn.nn.FieldType(C4group, C[1]*[C4group.regular_repr])\n",
    "        self.type_out = e2cnn.nn.FieldType(C4group, nz*[C4group.irrep(2)])\n",
    "        \n",
    "        \n",
    "        self.conv1 = e2cnn.nn.R2Conv(self.type_in, self.type_hid1,  kernel_size=3,padding=1,padding_mode='circular')\n",
    "        self.relu1 = e2cnn.nn.ReLU(self.type_hid1)\n",
    "        self.conv2 = e2cnn.nn.R2Conv(self.type_hid1, self.type_hid2,  kernel_size=3,padding=1,padding_mode='circular')\n",
    "        self.relu2 = e2cnn.nn.ReLU(self.type_hid2)\n",
    "        self.conv3 = e2cnn.nn.R2Conv(self.type_hid2, self.type_out, kernel_size=3,padding=1,padding_mode='circular')\n",
    "        \n",
    "    def forward(self,x):\n",
    "        \n",
    "        x = e2cnn.nn.GeometricTensor(x, self.type_in)\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.conv3(x)\n",
    "      \n",
    "        return x.tensor\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5ed184-009e-4ee1-a076-85b1c2d6c7b4",
   "metadata": {},
   "source": [
    "The hidden layers have the 'regular' representation, which for the cyclic group just corresponds to all the cyclic permutations. Kind of confusing, but easy to type!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d308c349-7c2a-4af3-8136-c56338fa23b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "N=4\n",
    "C4group = e2cnn.gspaces.Rot2dOnR2(N = N)\n",
    "x=torch.from_numpy(np.random.rand(1,N,1,1))\n",
    "x=e2cnn.nn.GeometricTensor(x, e2cnn.nn.FieldType(C4group, [C4group.regular_repr]))\n",
    "for g in C4group.testing_elements:\n",
    "    # Matthew 20:16\n",
    "    print('Rotation by '+str(g*90)+' degrees is '+str(g)+' cyclic permutations for regular representation')\n",
    "    print(x.transform(g))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7dde6c-3434-4f8a-b66f-417e46c3091f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=torch.from_numpy(np.random.rand(1,1,1,1))\n",
    "x=e2cnn.nn.GeometricTensor(x, e2cnn.nn.FieldType(C4group, [C4group.trivial_repr]))\n",
    "for g in C4group.testing_elements:\n",
    "    # Matthew 20:16\n",
    "    print('Rotation by '+str(g*90)+' degrees, no effect for trivial representation')\n",
    "    print(x.transform(g))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fed1af-e03f-43d7-b5df-88a24f17e713",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=torch.from_numpy(np.random.rand(1,1,1,1))\n",
    "x=e2cnn.nn.GeometricTensor(x, e2cnn.nn.FieldType(C4group, [C4group.irrep(2)]))\n",
    "for g in C4group.testing_elements:\n",
    "    # Matthew 20:16\n",
    "    print('Rotation by '+str(g*90)+' degrees = '+str(g)+' sign changes for sign representation')\n",
    "    print(x.transform(g))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9e046a-14af-4e7d-9377-de5769a1dd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=torch.from_numpy(np.random.rand(1,2,1,1))\n",
    "x=e2cnn.nn.GeometricTensor(x, e2cnn.nn.FieldType(C4group, [C4group.irrep(1)]))\n",
    "for g in C4group.testing_elements:\n",
    "    # Matthew 20:16\n",
    "    print('Rotation by '+str(g*90)+' degrees = rotation as for vector for irrep(1)')\n",
    "    print(x.transform(g))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7bb098c-81a2-41a7-a4c5-ce189cfe7a9c",
   "metadata": {},
   "source": [
    "Note, when we combined our input variables in the most natural way: \\\n",
    " &emsp;  inputFields = np.concatenate((u, v, w),axis=1) \\\n",
    "The resulting order of each sample was \\\n",
    "\\[u(k=0), u(k=1), u(k=2),..., u(k=# vert levels - 1), v(k=0), v(k=1), v(k=2),..., v(k=# vertical levels - 1)\\] \\\n",
    "In order for the e2cnn library to associate the u,v variables as components of the same vector, we need to instead have \\\n",
    " \\[u(k=0),  v(k=0), u(k=1), v(k=1), u(k=2), v(k=2),..., u(k=# vert levels - 1), v(k=# vertical levels - 1)\\] \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b80c7f1-0bff-4302-bb87-fd994f5a2140",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_input(inputFields_in,nz):\n",
    "    #Resulting order is\n",
    "    #u(k=0),v(k=0),u(k=1),v(k=1),u(k=2),v(k=2),...,w(k=0),w(k=1),w(k=2),....\n",
    "    inputFields_out=inputFields_in.copy()\n",
    "    for v in range(2):\n",
    "        for k in range(nz):\n",
    "            inputFields_out[:,2*k+v,:,:]=inputFields_in[:,v*nz+k,:,:]\n",
    "\n",
    "    return inputFields_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f0914c-0b10-4e4d-aa2a-cf7156dfe6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputFields = reshape_input(np.concatenate((u, v, w),axis=1),nz)\n",
    "outputFields = tau12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596098bf-02c7-45bd-a546-0a7d6541c2c5",
   "metadata": {},
   "source": [
    "Apart from the reshaping explained above, the following cells proceed just as we did with pytorch before. \\\n",
    "Note, even the loss and optimizers are being set with the torch.nn and torch.optim modules, not e2cnn.nn and e2nn.optim (which doesn't exist)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50656932-2092-4aeb-92e9-553b1d2c64c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test = torch.from_numpy(inputFields[mask]).float().to(device), torch.from_numpy(inputFields[~mask]).float().to(device)\n",
    "y_train, y_test = torch.from_numpy(outputFields[mask]).float().to(device), torch.from_numpy(outputFields[~mask]).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20b4431-8636-4ea6-b0c3-0097697b8020",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=e2cnnCNN(x_train.shape, nz).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de61f289-0f01-4cbd-ae1f-51bcb28f30ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline=pytorchCNN(x_train.shape,nz).float().to(device)\n",
    "summary(baseline,x_train.shape[1:])\n",
    "summary(model,x_train.shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0855dc-8fe1-42c0-8fa3-83a7d6893c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters())#,lr=0.001)\n",
    "criterion = torch.nn.MSELoss() # MSE loss function\n",
    "validation_loss = list()\n",
    "train_loss = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9610bc-d1f9-404d-a2fd-e414dfa89b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 400 #Number of epochs\n",
    "for epoch in range(n_epochs):\n",
    "    train_model(model,x_train,y_train,criterion,optimizer)\n",
    "    # train_loss.append(test_model(model,x_train,y_train,criterion,optimizer, 'train'))\n",
    "    # validation_loss.append(test_model(model,x_test,y_test,criterion,optimizer))\n",
    "    train_loss.append(test_model(model,x_train,y_train,criterion,optimizer, None))\n",
    "    validation_loss.append(test_model(model,x_test,y_test,criterion,optimizer,None))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d7af1d-df84-4ac9-a540-b881eb41da7d",
   "metadata": {},
   "source": [
    "One small difference worth noting is that the e2cnn does seem to take longer to train than the pytorch. For instance with my data, we are arguable overfitting after 200 epochs for the pytorch model, but the loss curve of the e2cnn is still smoothly decreasing after 400 epochs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918b7f7e-a5b5-4d5c-8669-8a819da45fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_losses(validation_loss,train_loss)\n",
    "plot_losses(validation_loss,train_loss,startEpoch=len(validation_loss)-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d742c86-ec67-46ac-9ad9-06397f4839bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction=model(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d745032d-617b-4477-9b68-792316e2cb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to assess if some hyperparameter tuning is necessary for reasonable performance if using your own data\n",
    "# kplot=nz//2\n",
    "# tplot=y_test.shape[0]//2\n",
    "# plot_contour(y_test,prediction,tplot,kplot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ceb1945-4134-46f3-b7c9-a440be832f72",
   "metadata": {},
   "source": [
    "As before, we want to compare predictions made from unrotated and rotated inputs, so we have to rotate the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb0efd2-3a53-4cd5-9a35-3bce5c54dec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputFields_rotated,outputFields_rotated = myrotate(np.stack((u,v,w)),outputFields,krot=1,out_type='sign')\n",
    "inputFields_rotated=reshape_input(inputFields_rotated,nz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4caa59d6-d42f-40bd-a425-ec0075685caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_rotated, x_test_rotated = torch.from_numpy(inputFields_rotated[mask]).float().to(device), torch.from_numpy(inputFields_rotated[~mask]).float().to(device)\n",
    "y_train_rotated, y_test_rotated = torch.from_numpy(outputFields_rotated[mask]).float().to(device), torch.from_numpy(outputFields_rotated[~mask]).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c1ab55-c995-431f-8e94-f0eacb89058f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and possibly modify if need to convince yourself myrotate() is working as intended\n",
    "# plot_contour(x_test[:,0:2*nz:2],x_test_rotated[:,1:2*nz+1:2],tplot,kplot,text=['Original, u','Rotated, v'])\n",
    "# plot_contour(x_test[:,-nz:],x_test_rotated[:,-nz:],tplot,kplot,text=['Original, w','Rotated, w'])\n",
    "# plot_contour(y_test,-y_test_rotated,tplot,kplot,text=['Original, tau_12','Rotated, -tau_12'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052ae64a-42f1-47de-b2da-0769c5cc6911",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_rotated=model(x_test_rotated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f657310-2e88-494d-ac9d-b4127fbba970",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_contour(y_test,prediction,tplot,kplot)\n",
    "plot_contour(-y_test_rotated,-prediction_rotated,tplot,kplot,text=[\"Rotated, true\",\"Predicted from rotated input\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16616f41-5fde-4bf1-bee5-ef4028cc1891",
   "metadata": {},
   "source": [
    "Unlike, pytorch, the rotated input leads to rotated output from the e2cnn version which is precisely what we would obtain if we simply rotated after prediction from the original data. \\\n",
    "Equivariance!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b11e601-b212-4b0c-98c7-4c35e02efdba",
   "metadata": {},
   "source": [
    "## Coding activity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b6725e-3bd8-42cf-993b-10197d8584ca",
   "metadata": {},
   "source": [
    "In my example, we took the 3 components of velocity and predicted 1 component, tau_12, of the momentum flux. \\\n",
    "Let's write a new model which will take the same input but instead output the 3 shear components of momentum flux, tau_12, tau_13, and tau_23. Try and translate this problem to your own data if necessary, e.g. if you looked at vertical buoyancy flux, <w'b'> try to include <u'b'> and <v'b'>. \n",
    "You will also need to modify the model definition. \\\n",
    "Based on your choices of output, you will need to modify the model definition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04eef97-8246-47f0-b174-e1d1fe2ab4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class e2cnnCNN(torch.nn.Module):\n",
    "    def __init__(self, input_shape, nz):\n",
    "        super(e2cnnCNN, self).__init__()\n",
    "        \n",
    "       # ???\n",
    "        \n",
    "    def forward(self,x):\n",
    "        \n",
    "        x = e2cnn.nn.GeometricTensor(x, self.type_in)\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.conv3(x)\n",
    "      \n",
    "        return x.tensor\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685970f7-b5af-4294-939c-3dca5498a68a",
   "metadata": {},
   "source": [
    "Because the additional components form a vector in the horizontal planes, \\[tau_13, tau_23\\] (or \\[<u'b'>, <v'b'>\\], etc.), you may need to define a reshape_output, similar to my reshape_input function, which takes np.concatenate((tau_12,tau_13,tau_23), axis=1) as an input and outputs the same variables but reordered as required by the e2cnn.FieldType for the output layer, which you will need to define above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78aca06b-2238-4255-a5a8-8de0658c5843",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_output(outputFields_in,nz):\n",
    "    #Resulting order is ???\n",
    "\n",
    "    return outputFields_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f6a44e-e2e7-48d5-a052-d3a820ec2e7c",
   "metadata": {},
   "source": [
    "As with horizontal velocity vector, we need to use the same scaling for each component of the output vectors. I have gone ahead and done that for the example with my data, modify as necessary for your own data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff06e03-e1ae-48d1-afaf-879cda690fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "taui3std = np.std(np.sqrt(ds['tau13'].values**2+ds['tau23'].values**2))\n",
    "\n",
    "#tau12=np.transpose(scale(ds['tau12'].values,mean=0), [3,0,1,2])\n",
    "tau13=np.transpose(scale(ds['tau13'].values,mean=0,std=taui3std), [3,0,1,2])\n",
    "tau23=np.transpose(scale(ds['tau23'].values,mean=0,std=taui3std), [3,0,1,2])\n",
    "\n",
    "outputFields = reshape_output(np.concatenate((tau12,tau13,tau23), axis=1),nz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3e97cd-de9c-455b-a515-8f3cc25c38df",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test = torch.from_numpy(inputFields[mask]).float().to(device), torch.from_numpy(inputFields[~mask]).float().to(device)\n",
    "y_train, y_test = torch.from_numpy(outputFields[mask]).float().to(device), torch.from_numpy(outputFields[~mask]).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849fe1d9-2619-4c0b-85ad-dec42940d450",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=e2cnnCNN(x_train.shape,nz).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbb1ec0-2b90-4970-859b-dedc8efbb54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters())#,lr=0.001)\n",
    "criterion = torch.nn.MSELoss() # MSE loss function\n",
    "validation_loss = list()\n",
    "train_loss = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8beef7-ae25-4f87-a62f-ba9e07289c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 400 #Number of epochs\n",
    "for epoch in range(n_epochs):\n",
    "    train_model(model,x_train,y_train,criterion,optimizer)\n",
    "    # train_loss.append(test_model(model,x_train,y_train,criterion,optimizer, 'train'))\n",
    "    # validation_loss.append(test_model(model,x_test,y_test,criterion,optimizer))\n",
    "    train_loss.append(test_model(model,x_train,y_train,criterion,optimizer, None))\n",
    "    validation_loss.append(test_model(model,x_test,y_test,criterion,optimizer,None))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868d7386-5c83-4a75-babd-0eae26537f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_losses(validation_loss,train_loss,startEpoch=len(validation_loss)-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fc267b-1c7a-4985-854b-2f2884596a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction=model(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07783a4e-d4c5-46a7-a199-ab47d47cd416",
   "metadata": {},
   "outputs": [],
   "source": [
    "kplot=nz//2\n",
    "tplot=y_test.shape[0]//2\n",
    "plot_contour(y_test[:,0:nz],prediction[:,0:nz],tplot,kplot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630a8d68-7c5b-4faf-a1be-e477607a6d55",
   "metadata": {},
   "source": [
    "As before, it will be nice to check the predictions against some manually rotated data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b100c57-e7e5-4285-ad7a-b06cc1b29853",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate(inputFields_in,outputFields_in,krot,out_type='scalar'):\n",
    "    inputFields_out=np.empty(inputFields_in.shape)\n",
    "    outputFields_out=np.empty(outputFields_in.shape)\n",
    "    \n",
    "    # first move values to new location on grid\n",
    "    \n",
    "    # second rotate the vector, change sign rep, etc.\n",
    "\n",
    "    # final shape should have variable concatenated along axis=1                  \n",
    "    inputFields_final=np.concatenate([inputFields_out[i] for i in range(inputFields_out.shape[0])],axis=1)\n",
    "    outputFields_final=np.concatenate([outputFields_out[i] for i in range(outputFields_out.shape[0])],axis=1)\n",
    "    \n",
    "\n",
    "\n",
    "    return inputFields_final,outputFields_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bf0b81-6eed-493a-aa48-b63e4f6fca98",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputFields_rotated,outputFields_rotated = rotate(np.stack((u,v,w)),np.stack((tau12,tau13,tau23)),krot=1,out_type='sign')\n",
    "inputFields_rotated=reshape_input(inputFields_rotated,nz)\n",
    "outputFields_rotated=reshape_output(outputFields_rotated,nz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59ce14e-1967-466b-ab8a-6b4a622776f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_rotated, x_test_rotated = torch.from_numpy(inputFields_rotated[mask]).float().to(device), torch.from_numpy(inputFields_rotated[~mask]).float().to(device)\n",
    "y_train_rotated, y_test_rotated = torch.from_numpy(outputFields_rotated[mask]).float().to(device), torch.from_numpy(outputFields_rotated[~mask]).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e859fd38-d41f-431d-9485-69d7e8dbcb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "nz=u.shape[1] # might need to change index for your data\n",
    "plot_contour(x_test[:,0:2*nz:2],x_test_rotated[:,1:2*nz+1:2],tplot,kplot,text=['Original, u','Rotated, v'])\n",
    "plot_contour(x_test[:,-nz:],x_test_rotated[:,-nz:],tplot,kplot,text=['Original, w','Rotated, w'])\n",
    "plot_contour(y_test[:,nz:3*nz:2],y_test_rotated[:,nz+1:3*nz+1:2],tplot,kplot,text=['Original, tau_13','Rotated, tau_23'])\n",
    "plot_contour(y_test[:,0:nz],-y_test_rotated[:,0:nz],tplot,kplot,text=['Original, tau_12','Rotated, -tau_12'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3eed85-b1c2-4a8e-bb3a-b14cbf20f3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_rotated=model(x_test_rotated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0946d9d1-9a61-44a3-a1f6-fbbfbf5ac3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_contour(y_test[:,nz:3*nz:2],prediction[:,nz:3*nz:2],tplot,kplot)\n",
    "plot_contour(y_test_rotated[:,nz+1:3*nz+1:2],prediction_rotated[:,nz+1:3*nz+1:2],tplot,kplot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8ac0c1-8403-40c3-bd25-e75f1a1c8a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_quiver([y_test[:,nz:3*nz:2],y_test[:,nz+1:3*nz+1:2]],[prediction[:,nz:3*nz:2],prediction[:,nz+1:3*nz+1:2]],tplot,kplot)\n",
    "plot_quiver([y_test_rotated[:,nz:3*nz:2],y_test_rotated[:,nz+1:3*nz+1:2]],[prediction_rotated[:,nz:3*nz:2],prediction_rotated[:,nz+1:3*nz+1:2]],tplot,kplot,text=[\"True, Rotated\", \"Predicted, Rotated\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
